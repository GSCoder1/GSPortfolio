{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ed3c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/laxmimerit/NLP-Tutorials-with-HuggingFace/blob/main/NLP_with_HuggingFace_Tutorial_4_Summarization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd531e42-02da-4858-8807-7476380f680d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4.35.2', '0.25.0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import accelerate\n",
    "import transformers\n",
    "\n",
    "transformers.__version__, accelerate.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19be4719-5717-466e-a6fc-5387bd901703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import AdamWeightDecay\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "from rouge import Rouge\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace39254-98b6-4d44-8039-c0cb05c3628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('cnn_dailymail', '3.0.0', split='train[:15%]')\n",
    "dataset_test = load_dataset('cnn_dailymail', '3.0.0', split='test[0:100]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0624b6-0994-4ba5-9fdf-49fd5c4e4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d2d3e57-a456-424c-9781-0d996f1c3b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 34453\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 8614\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2628bda3-8d4d-435c-895b-500eab0b862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "learning_rate = 4e-5\n",
    "weight_decay = 0.01\n",
    "epochs = 3\n",
    "warm_up=500\n",
    "training_steps = 7500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdc60641-1c64-4a2a-b9dd-793e47091eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 768, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizerBart = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "modelBart = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "modelBart.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04d34f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(batch):\n",
    "    encodings = tokenizerBart(batch['article'], text_target=batch['highlights'],\n",
    "                        max_length=1024, truncation=True)\n",
    "\n",
    "    encodings = {'input_ids': encodings['input_ids'],\n",
    "               'attention_mask': encodings['attention_mask'],\n",
    "               'labels': encodings['labels']}\n",
    "\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c51ad7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a56b0a490f47f287169073a0988547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/34453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22dfad53e4344a180d4838fa80c1a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8614 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(get_feature, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd02db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 34453\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 8614\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6ef5f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['input_ids', 'labels', 'attention_mask']\n",
    "dataset.set_format(type='pt', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07374e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizerBart, model=modelBart, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "266fecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = 'bart',\n",
    "    num_train_epochs=epochs,\n",
    "    warmup_steps = warm_up,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay = weight_decay,\n",
    "    max_grad_norm=1.0,\n",
    "    logging_steps = 10,\n",
    "    evaluation_strategy = 'steps',\n",
    "    eval_steps=250,\n",
    "    save_steps=1e6,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=modelBart, \n",
    "                  args=training_args, \n",
    "                  tokenizer=tokenizerBart,\n",
    "                  data_collator=data_collator,\n",
    "                  train_dataset = dataset['train'], \n",
    "                  eval_dataset = dataset['test'], \n",
    "                  )\n",
    "\n",
    "optimizer = torch.optim.Adam(modelBart.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warm_up, num_training_steps=training_steps)\n",
    "trainer.optimizer = optimizer\n",
    "trainer.lr_scheduler = scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b90702b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b05abd5-e148-496b-9795-18220b18cb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5991c3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 768, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelBart.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d4e1197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3228' max='3228' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3228/3228 2:07:32, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.498800</td>\n",
       "      <td>2.101984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.434100</td>\n",
       "      <td>2.098762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.875100</td>\n",
       "      <td>2.447793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.672300</td>\n",
       "      <td>3.020176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>4.200200</td>\n",
       "      <td>3.645432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.661600</td>\n",
       "      <td>4.239052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>4.983100</td>\n",
       "      <td>4.706543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>5.265000</td>\n",
       "      <td>4.987002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>5.325400</td>\n",
       "      <td>5.141323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>5.443800</td>\n",
       "      <td>5.270058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>5.619500</td>\n",
       "      <td>5.359497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>5.705100</td>\n",
       "      <td>5.450592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3228, training_loss=4.407310738144015, metrics={'train_runtime': 7654.5045, 'train_samples_per_second': 13.503, 'train_steps_per_second': 0.422, 'total_flos': 5.924065631597568e+16, 'train_loss': 4.407310738144015, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96353c9a-3a0f-49e2-ac7b-6e9b345526ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "211007e2-1e28-480f-8832-85ab3bbf7a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_preds(tokenizer, model):\n",
    "    evaluate = []\n",
    "    for element in dataset_test['article']:\n",
    "        tokenized = tokenizer([element], max_length=1024, truncation=True, return_tensors='pt').to('cuda')\n",
    "        pred = model.generate(**tokenized, max_length=128)\n",
    "        evaluate.append(pred)\n",
    "    pred = []\n",
    "    for article in evaluate:\n",
    "        new_article = tokenizer.decode(article[0], skip_special_tokens=True)\n",
    "        pred.append(new_article)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e28d5ab9-f2ab-4640-8179-3de75ba8036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_preds(dataset):\n",
    "    actual = []\n",
    "    for summary in dataset['highlights']:\n",
    "        actual.append(summary)\n",
    "    return actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68293f39-176c-450a-ae73-88e56984ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Bart = generate_preds(tokenizerBart, modelBart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "640e25c5-245d-468e-b481-2e133d70c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_Bart = actual_preds(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d83865df-6a96-4368-89c9-b776c24d3721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NEW: The Palestinian Palestinian Palestinian Palestinians in the court court.\\nHe says he says he was accused of the U.N.S.SS.\\nHe was accused accused of Palestinian Palestinian.',\n",
       " 'NEW: The police say they have been killed in the death.\\nHe says he says he was found found in a death.',\n",
       " \"NEW: The Iranian Iranian Iranian Iran's Iranian Iran.\\nHe says he says.\\nNEW: Iran's Iran says he was not not not have been been in Iran.\",\n",
       " 'NEW: The hospital,000 people,000,000000 people.\\nHe says he says he was killed in the hospital.',\n",
       " 'NEW: Student Student student student student students students students.\\nThe student student says he says.',\n",
       " \"NEW: New York's new new new school school school.\\nHe says he was not not not to be in the school.\",\n",
       " 'NEW: The U.S.SS.N.S,000 people were killed.\\nThe death death of the death of death death death.\\nHe says he was killed in the death.',\n",
       " 'NEW: The death of the death death of death.\\nHe says he says he was killed.\\nThe death of his death death death in the death.',\n",
       " \"NEW: The U.S.SS.N.S''S. says.\\nHe says he says he was killed in the storm.\",\n",
       " 'NEW: The \"The show show show\"\\nHe says he says he\\'s \"I\"\\n\"\\nThe show is a \"We\"\"\"\\nIt\\'s \"It is not not not have been been been in the show.',\n",
       " 'NEW: The police say he was arrested in the police say.',\n",
       " 'NEW: The \"We\\'re\\'re \"The \"I\"\"\"\\nHe says he says he was found in the death.\\nHe was a \"I\\'m\"\\n\"',\n",
       " \"NEW: New York's death of the death death of death.\\nHe says he says he was killed in the death.\",\n",
       " 'NEW: Obama says he says it is a new-year-1.\\nHe says it will be not not not to be in the same same-old.\\nThe GOP says he was not not have been been in the law.',\n",
       " 'NEW: New York\\'s first first first time of the first first-year-old.\\nHe says he was a \"It\\'s \"I\\'m\"\\n\"',\n",
       " 'NEW: Obama says he says it is not not not to be a new new new.\\nHe says it will have been been in the same-year-1, he says.',\n",
       " 'NEW: The U.S.SS.N.S,000 people were killed.\\nHe says it was killed in the death of the death.\\nThe death of death death,000000 people have been killed.',\n",
       " 'NEW: The U.S.SS.N.Sss.\\nHe says he says he was found in the crash.',\n",
       " \"NEW: It's family, he says he says.\\nHe says he had been been been killed.\\nShe says he was not not not have been killed in the family.\",\n",
       " 'NEW: The U.S.SS.\\nHe says he says he was a new new-year-old says.\\nHe is a a new-old of the U.\\nNEW: Obama says it is not not not have been been in the world.\\nThe U.',\n",
       " \"NEW: It's family, he says he says.\\nHe says he was not not not have been been in the boat.\",\n",
       " \"NEW: U.SS.S.N.S., Iran says.\\nHe says it is not not not have been in Iran.\\nThe Iran's Iran says it will have been been in the Iran.\",\n",
       " 'NEW: The U.S.SS.5 million,000 people.\\nHe says he says it will have been been been in the drought.',\n",
       " 'NEW: The U.S.SS.N.S, police say.',\n",
       " 'NEW: The Iranian Iranian Iranian Iran has been been in Iran.',\n",
       " \"NEW: The U.S.SS.N.\\nThe government says he says it is a new new new rights.\\nHe says it has been been in the government.\\nThe police say it was accused of the death of the world's death.\",\n",
       " 'NEW: The \"We have been been been in the death.\\nHe says he was a \"The family\"\"\\n\"',\n",
       " \"NEW: New York's first first first time of the world.\\nHe says he says he was found in the world's home.\",\n",
       " 'NEW: Obama says he says it is a nuclear nuclear nuclear.\\nHe says he was not not not have been been in Iran.\\nNEW: The Obama says it says.',\n",
       " 'NEW: The \"We\\'re\\'re\\'re not not not been been been in the family.\\nHe says he says it\\'s \"We\"\"\\n\"',\n",
       " 'NEW: The police say they have been killed in the death.\\nHe says he was found in the police say.',\n",
       " \"NEW: The U.S.SS.N.S'\\nHe says he says he was not not not have been in the world.\",\n",
       " 'NEW: The \"We\\'re\\'re\\'re not not not have been been been in the world.\\nHe says it is not not to the world world.',\n",
       " 'NEW: The police police police say they were killed in the police say.\\nThe police say it was found in the shooting.\\nHe says he was found on the police.',\n",
       " 'NEW: The U.S.SS.N.S,000 million.\\nThe eclipse eclipse eclipse of the eclipse eclipse.',\n",
       " 'NEW: The Somali Somali Somali,000 people are in Somalia.\\nHe says he says it is a government.\\nS.S.N.Sababab says.',\n",
       " \"NEW: The U.S.SS.N.S'''\\nHe says he says it's first first first-year-1,000 people.\\nHe has been been been in the first first time.\",\n",
       " 'NEW: The NCAA NCAA NCAA of the NCAA NCAA.',\n",
       " 'NEW: The judge says he says she says.\\nHe says he was accused of the court court.\\nThe court court court is not not not have been in the court.',\n",
       " 'NEW: It\\'s first first first time of the world.\\nHe says he says it\\'s \"It\"\"\\n\"\\nThe first first-year-old says he\\'s \"I\\'m\"\"',\n",
       " 'NEW: The U.S.SS.N.S., the world.',\n",
       " 'NEW: The U.S.SS.N.\\nThe government says it says he says.\\nHe says it is not not not been been been in the law.\\nNEW: U. says.',\n",
       " 'NEW: The crash in the crash.',\n",
       " 'NEW: The U.S.SS.N.S., Korean Korean Korean Korea.\\nHe says he was accused of the court.\\nThe police say he says he says.',\n",
       " 'NEW: The police police say they have been been been arrested.\\nHe says he was arrested in the police say.\\nThe police say he was found in the death.',\n",
       " 'NEW: The Thai Thai Thai Thailand Thailand.',\n",
       " 'NEW: The Manning is a man of the prison.\\nHe has been been been in the death.\\nNEW: \"We have been been charged with the death\"',\n",
       " \"NEW: Iran's Iran Iran Iran says.\\nNEW: Obama says he says it's Iran.\\nHe says it is not not not to Iran.\",\n",
       " \"NEW: The $1 million million million,000 million million.\\nHe says it's $1.S.5 million million in the world.\\nThe $1,000000 million.\",\n",
       " 'NEW: \"We\\'re\\'re\\'re \"I\"\"\\nHe says he says it\\'s \"I\\'\\'\\'\"\\n\"',\n",
       " 'NEW: The \"I\\'ve\\'ve\\'ve\\'re\\'re\\'re not not not have been been in the law.\\nHe says he says it is a \"I\\'m\"\\n\"\\nHe was accused of the case of the same-year-old says.',\n",
       " 'NEW: The gay gay gay-year-old says.\\nHe says he says it is not not not been been in the marriage.',\n",
       " 'NEW: The U.S.SS.N.NN.000 people.',\n",
       " \"NEW: The U.S.SS.NN.S., Japan.\\nHe says it's first first first time of the U.N.\\nThe U.1-year-old says.\",\n",
       " \"NEW: The U.S.SS.N.S'S.\\nThe government says it's government says he says.\\nHe says it is not not not have been killed in Yemen.\",\n",
       " 'NEW: The police say they have been been been in the first first.\\nHe says he says he was found in the same-year-old.',\n",
       " 'NEW: \"I have been been been in the first first first-year-old.\\nHe says he has been been on the team.\\nThe first first time of the first time to be on the first-0.',\n",
       " 'NEW: The U.S.SS. officials say.\\nHe says he says he was killed in the death.\\nThe police say they have been been killed.',\n",
       " 'NEW: The U.S.SS.N. says.',\n",
       " 'NEW: The police say he says he says.\\nHe says he was found in the police say.',\n",
       " 'NEW: The U.S.SS.N.000 people.',\n",
       " 'NEW: The charges charges charges of charges charges.\\nHe says he says he was accused of the charges.',\n",
       " 'NEW: The film film film is a film film.\\nThe film film\\'s \"The film\"\"',\n",
       " 'NEW: \"The show show show of the show show.\\nHe says he says he was not not not to show.',\n",
       " 'NEW: The police say they have been charged in the case.\\nHe says he was arrested in the charges.',\n",
       " 'NEW: The show show show of the show show.\\nHe says he says he was not not not to show.',\n",
       " 'NEW: The \"I\\'re\\'re\\'re not not not to be a new new new.\\nHe says it is a \"We\"\\n\"\"\\nHe was not not have been been been in the world.\\nShe says he says it\\'s \"I\\'m\"',\n",
       " 'NEW: The \"I\\'re\\'re\\'re not not not a new new new life.\\nHe says he was a \"I\"\"\\n\"\\nHe is a \"It\\'s \"I\\'m\"',\n",
       " 'NEW: The police police say they have been been in the police say.\\nHe says he says he was arrested in the official says.',\n",
       " 'NEW: The U.S.SS. U.N.S, Syria.\\nNEW: U. officials say.',\n",
       " 'NEW: The U.S.SS.N.NN. says.',\n",
       " 'NEW: It\\'s first first time in the first first first-year-old.\\nHe says he was in the death of the first time.\\nShe says he says he\\'s \"I\\'m\"',\n",
       " \"NEW: The Chinese Chinese Chinese China's government government.\\nHe says he says he was accused of China.\",\n",
       " 'NEW: The \"We have been been been in the death.\\nHe says he says he was found in the family, he says.\\nShe says it\\'s \"I\\'m\"\\n\"',\n",
       " 'NEW: The police police say.',\n",
       " 'NEW: The Senate Senate Senate of the U.S.SS. says.\\nHe says he says he was not not not to be to be not not have been in the GOP.',\n",
       " 'NEW: The media media says it is on the world.\\nHe says it says it\\'s \"It says it\"\\n\"',\n",
       " 'NEW: U.SS.S. U.N.Sihadihadihad.\\nHe says he says he was in the flight.\\nThe flight flight flight of the flight flight in the United States.',\n",
       " 'NEW: The U.S.SS.\\nHe says he says he was accused of the death.\\nHe has been been been in the death of the U.\\nThe U.N.Sararar says.',\n",
       " 'NEW: The fire fire fire in the fire fire.',\n",
       " 'NEW: The GOP GOP GOP, he says he says.\\nHe says it is a new new new-year-old says.',\n",
       " 'NEW: The U.S.SS.000 people were killed.\\nHe says he says he was killed in the attack.',\n",
       " 'NEW: The U.S.SS.5 million million.\\nHe says he was found in $1,000 million.',\n",
       " 'NEW: The police say he was arrested in the death.\\nHe says he was accused of the death of death.',\n",
       " 'NEW: U.S.SS. officials say.',\n",
       " 'NEW: The \"We\\'re\\'re\\'re not not not have been been been in the world.\\nHe says it is not not to be not not been been on the death.\\nShe says he says it\\'s \"We\"',\n",
       " 'NEW: The U.S.SS.N.S,000 people.\\nNEW: U. officials say.',\n",
       " 'NEW: The police say he was accused of the first first-year-old.\\nHe says he says he was not not not been been been in the police say.\\nThe police say they have been been charged with the death.',\n",
       " 'NEW: The crash crash crash in the crash.\\nThe crash crash crashed crashed crashed.\\nHe says the crash in a crash crash.',\n",
       " 'NEW: The \"The film\"\"\"\\nThe film is a \"I\"\\nHe says it\\'s \"The movie\"\"',\n",
       " 'NEW: The band\\'s \"The band\"\\nHe says he says he will be in the band.\\nThe band is not not not been been in the death.\\nHe is the first first first-year-old of the death of the world.',\n",
       " 'NEW: The film film film is a film film.\\nThe film film\\'s \"The film\"\\nThe movie\\'s \"I\"\\n\"',\n",
       " 'NEW: The tornado tornado,000 people were killed in the tornado.\\nHe says he says he was killed in a tornado, but they say.\\nNEW: \"The tornado\"',\n",
       " 'NEW: The police say he was killed in the death.\\nHe says he says he was found in the police say.\\nThe police say they say they were killed.',\n",
       " 'NEW: The judge says he says he had been been charged with a court.\\nHe says he was accused of the court.',\n",
       " 'NEW: New York\\'s \"I\"\"\\nHe says he says he was found in the world.\\nHe was found to the first first first-year-1, he says.\\nIt\\'s \"It\"',\n",
       " 'NEW: The woman, she was found in her her her she she she says.\\nHe says she was accused of her her husband, she says she says he was in her woman.',\n",
       " \"NEW: New York's first first first-year-0.\\nHe says he says he was found in the first first time.\",\n",
       " 'NEW: A A A-year-old of the first first first time.\\nHe says he says it is a \"I\\'m\"\\n\"\\nHe has been been been in the same same-old says.',\n",
       " 'NEW: \"I\"\"\"\\nThe film\\'s \"I\\'m\"\"']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_Bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca086126-ca61-45f4-9b42-c4d50aeae589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge_scores(actual_summary, predicted_summary):\n",
    "    rouge = Rouge()\n",
    "    try: \n",
    "        if (len(actual_summary) == len(predicted_summary)):\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(f\"lengths of actual and predictions don't match: {e}\")\n",
    "    score_total1 = 0\n",
    "    score_total2 = 0\n",
    "    score_totalL = 0\n",
    "    for i in range(0, len(actual_summary)):\n",
    "        scores = rouge.get_scores(predicted_summary[i], actual_summary[i])\n",
    "        \n",
    "        score_total1 += scores[0]['rouge-1']['f']\n",
    "        score_total2 += scores[0]['rouge-2']['f']\n",
    "        score_totalL += scores[0]['rouge-l']['f']\n",
    "    return score_total1 / len(actual_summary), score_total2 / len(actual_summary), score_totalL / len(actual_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be2ae4be-7650-461e-9ac0-faf28dfc6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge1Bart, rouge2Bart, rougelBart = get_rouge_scores(actual_Bart,pred_Bart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a25d3a8a-3547-4f34-a7a4-3fb298e0a0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1316 0.0162 0.1267\n"
     ]
    }
   ],
   "source": [
    "print(round(rouge1Bart, 4), round(rouge2Bart, 4), round(rougelBart, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "510a9f45-2be8-4674-9af3-32c59189eaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_Bart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0efcc7c3-bde1-4489-9c0d-a6815beaddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1d6fccf-505b-406d-a415-2a7ec1214e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2154' max='2154' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2154/2154 02:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78bb9f47-30e5-44ac-bd7f-dfb90c421b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 5.525334358215332,\n",
       " 'eval_runtime': 157.1202,\n",
       " 'eval_samples_per_second': 54.824,\n",
       " 'eval_steps_per_second': 13.709,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
